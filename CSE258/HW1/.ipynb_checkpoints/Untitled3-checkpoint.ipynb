{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from math import exp\n",
    "from math import log\n",
    "import csv\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseData(fname):\n",
    "  for l in urllib.urlopen(fname):\n",
    "    yield eval(l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print \"Reading data...\"\n",
    "csvfile = file('winequality-white.csv','rb')\n",
    "reader = csv.reader(csvfile)\n",
    "print \"done\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for line in reader:\n",
    "    data.append(line[0].split(';'))\n",
    "del data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Conversion from string to float\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data[i])):\n",
    "        data[i][j]=float(data[i][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtain the quality\n",
    "N=12\n",
    "y=[x[N-1] for x in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtain the evaluation\n",
    "y_evaluation=[]\n",
    "for quality in y:\n",
    "  if quality > 5:\n",
    "    y_evaluation.append(1)\n",
    "  else:\n",
    "    y_evaluation.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Extract the features data\n",
    "for features in data:\n",
    "    del features[N-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:len(data)/2]\n",
    "y_train = y_evaluation[:len(data)/2]\n",
    "X_test = X[len(data)/2:]\n",
    "y_test = y_evaluation[len(data)/2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a support vector classifier object, with regularization parameter C = 1000\n",
    "clf = svm.SVC(C=1000)   #\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy=  1.0\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = sum([z[0] == z[1] for z in zip(train_predictions, y_train)]) * 1.0 / len(train_predictions)\n",
    "print 'train_accuracy= ', train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy=  0.668027766435\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = sum([z[0] == z[1] for z in zip(test_predictions, y_test)]) * 1.0 / len(test_predictions)\n",
    "print 'test_accuracy= ', test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inner(x,y):\n",
    "  return sum([x[i]*y[i] for i in range(len(x))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1.0 / (1 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "      loglikelihood -= logit\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  print \"ll =\", loglikelihood\n",
    "  return -loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "  dl = [0.0]*len(theta)\n",
    "  for k in range(len(theta)):\n",
    "      sum = 0\n",
    "      for i in range(len(X)):\n",
    "        # Fill in code for the derivative\n",
    "        logit = inner(X[i], theta)\n",
    "        sum += X[i][k] * (1-sigmoid(logit))\n",
    "        if not y[i]:\n",
    "            sum -= X[i][k]\n",
    "      dl_temp = sum - 2 * lam * theta[k]\n",
    "      dl[k] = dl_temp\n",
    "  # Negate the return value since we're doing gradient *ascent*\n",
    "  return numpy.array([-x for x in dl])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll = -1697.51744519\n",
      "ll = -143194.900113\n",
      "ll = -8508.69061169\n",
      "ll = -1662.30572651\n",
      "ll = -1640.40856092\n",
      "ll = -1640.03814916\n",
      "ll = -1639.03949975\n",
      "ll = -1636.45792249\n",
      "ll = -1630.77442533\n",
      "ll = -1620.55739783\n",
      "ll = -1608.50105879\n",
      "ll = -1600.16288881\n",
      "ll = -1597.29785578\n",
      "ll = -1596.47865693\n",
      "ll = -1594.70979598\n",
      "ll = -1590.91731654\n",
      "ll = -1582.41530859\n",
      "ll = -1568.4144228\n",
      "ll = -1572.16480918\n",
      "ll = -1562.98451058\n",
      "ll = -1722.1864377\n",
      "ll = -1553.11941899\n",
      "ll = -1551.28247863\n",
      "ll = -1550.93347138\n",
      "ll = -1550.92435403\n",
      "ll = -1550.88829208\n",
      "ll = -1550.75056169\n",
      "ll = -1550.30379368\n",
      "ll = -1546.82746913\n",
      "ll = -1540.24521872\n",
      "ll = -1532.3436015\n",
      "ll = -1501.87894509\n",
      "ll = -1494.96452746\n",
      "ll = -1493.00529421\n",
      "ll = -1492.90039231\n",
      "ll = -1492.8236081\n",
      "ll = -1492.71329423\n",
      "ll = -1492.53289951\n",
      "ll = -1492.37805602\n",
      "ll = -1492.30775575\n",
      "ll = -1492.26556835\n",
      "ll = -1492.02672659\n",
      "ll = -1490.77384179\n",
      "ll = -1488.44202781\n",
      "ll = -1482.2015175\n",
      "ll = -1470.38581772\n",
      "ll = -1453.77901942\n",
      "ll = -1441.71969374\n",
      "ll = -1438.45018843\n",
      "ll = -1497.6694022\n",
      "ll = -1438.1651363\n",
      "ll = -1437.84903693\n",
      "ll = -1437.46297497\n",
      "ll = -1437.37965204\n",
      "ll = -1437.2770751\n",
      "ll = -1437.18724176\n",
      "ll = -1437.13693305\n",
      "ll = -1437.20154298\n",
      "ll = -1437.12748193\n",
      "ll = -1437.01026455\n",
      "ll = -1436.82956778\n",
      "ll = -1436.12234382\n",
      "ll = -1467.48393549\n",
      "ll = -1436.1057686\n",
      "ll = -1435.48712826\n",
      "ll = -1494.26836311\n",
      "ll = -1434.54323247\n",
      "ll = -1433.12702876\n",
      "ll = -1444.87525346\n",
      "ll = -1430.96154754\n",
      "ll = -1421.59788711\n",
      "ll = -1404.70361773\n",
      "ll = -1393.45483117\n",
      "ll = -1391.46872176\n",
      "ll = -1391.33178692\n",
      "ll = -1391.32033674\n",
      "ll = -1419.5364793\n",
      "ll = -1391.32032486\n",
      "ll = -1391.31703012\n",
      "ll = -1391.31424371\n",
      "ll = -1391.31292207\n",
      "ll = -1391.31212881\n",
      "ll = -1391.31176179\n",
      "ll = -1391.30953892\n",
      "ll = -1391.29932174\n",
      "ll = -1391.28149533\n",
      "ll = -1391.22467633\n",
      "ll = -1391.12476616\n",
      "ll = -1392.86853154\n",
      "ll = -1391.1152989\n",
      "ll = -1390.92746727\n",
      "ll = -1390.71081078\n",
      "ll = -1390.4788801\n",
      "ll = -1390.31652346\n",
      "ll = -1390.11875765\n",
      "ll = -1389.89408966\n",
      "ll = -1389.97455642\n",
      "ll = -1389.56415607\n",
      "ll = -1389.47158519\n",
      "ll = -1389.47089753\n",
      "ll = -1389.47082693\n",
      "ll = -1389.4707264\n",
      "ll = -1389.47048544\n",
      "ll = -1389.4700041\n",
      "ll = -1389.46755555\n",
      "ll = -1389.46572061\n",
      "ll = -1389.5506915\n",
      "ll = -1389.46547149\n",
      "ll = -1389.46374688\n",
      "ll = -1389.46303511\n",
      "ll = -1389.46247703\n",
      "ll = -1389.46141693\n",
      "ll = -1389.4595981\n",
      "ll = -1389.45748126\n",
      "ll = -1511.31150097\n",
      "ll = -1389.45741117\n",
      "ll = -1389.45631385\n",
      "ll = -1389.45608794\n",
      "ll = -1389.45606926\n",
      "ll = -1389.45606175\n",
      "ll = -1389.4560267\n",
      "ll = -1389.45595767\n",
      "ll = -1389.45582946\n",
      "ll = -1389.45566643\n",
      "ll = -1389.45554151\n",
      "ll = -1389.45548153\n",
      "ll = -1389.4553918\n",
      "ll = -1389.45559955\n",
      "ll = -1389.45534273\n",
      "ll = -1389.45518108\n",
      "ll = -1389.45490657\n",
      "ll = -1389.45481828\n",
      "ll = -1389.45465738\n",
      "ll = -1389.45460042\n",
      "ll = -1389.45454743\n",
      "ll = -1389.45438856\n",
      "ll = -1389.45398493\n",
      "ll = -1389.45337809\n",
      "ll = -1389.73484372\n",
      "ll = -1389.45312242\n",
      "ll = -1389.45254589\n",
      "ll = -1389.45222415\n",
      "ll = -1391.12647822\n",
      "ll = -1389.4520445\n",
      "ll = -1389.45197024\n",
      "ll = -1389.45192445\n",
      "ll = -1389.45682718\n",
      "ll = -1389.45188034\n",
      "ll = -1389.45153404\n",
      "ll = -1389.44975351\n",
      "ll = -1389.44442088\n",
      "ll = -1389.44323845\n",
      "ll = -1389.44204319\n",
      "ll = -1389.54614497\n",
      "ll = -1389.44194469\n",
      "ll = -1389.44056709\n",
      "ll = -1389.44691568\n",
      "ll = -1389.44015774\n",
      "ll = -1389.43751201\n",
      "ll = -1389.43067122\n",
      "ll = -1389.42853926\n",
      "ll = -1389.41592966\n",
      "ll = -1389.41068806\n",
      "ll = -1389.40723967\n",
      "ll = -1389.40543651\n",
      "ll = -1389.40264678\n",
      "ll = -1389.40154511\n",
      "ll = -1389.40107727\n",
      "ll = -1389.40084335\n",
      "ll = -1389.40027032\n",
      "ll = -1389.39940679\n",
      "ll = -1391.02276802\n",
      "ll = -1389.39934772\n",
      "ll = -1389.3981502\n",
      "ll = -1389.3969698\n",
      "ll = -1389.39613027\n",
      "ll = -1389.39529023\n",
      "ll = -1389.39486145\n",
      "ll = -1389.3944074\n",
      "ll = -1389.39215376\n",
      "ll = -1389.38761389\n",
      "ll = -1389.37324565\n",
      "ll = -1389.34229406\n",
      "ll = -2620.11597732\n",
      "ll = -1389.34209837\n",
      "ll = -1389.28805567\n",
      "ll = -1389.89265836\n",
      "ll = -1389.281938\n",
      "ll = -1389.21857467\n",
      "ll = -1389.18345994\n",
      "ll = -1389.17261971\n",
      "ll = -1391.95789189\n",
      "ll = -1389.16935597\n",
      "ll = -1389.16216602\n",
      "ll = -1389.14753171\n",
      "ll = -1389.13142894\n",
      "ll = -1389.09315019\n",
      "ll = -1389.05978986\n",
      "ll = -1388.98956236\n",
      "ll = -1388.94098394\n",
      "ll = -1389.13841257\n",
      "ll = -1388.91926629\n",
      "ll = -1388.89386094\n",
      "ll = -1388.89167182\n",
      "ll = -1388.88832844\n",
      "ll = -1388.88736141\n",
      "ll = -1388.88538001\n",
      "ll = -1388.88769831\n",
      "ll = -1388.88403446\n",
      "ll = -1388.88161422\n",
      "ll = -1388.87279575\n",
      "ll = -1388.87015696\n",
      "ll = -1388.87060657\n",
      "ll = -1388.86943966\n",
      "ll = -1388.87023023\n",
      "ll = -1388.86878811\n",
      "ll = -1388.86858095\n",
      "ll = -1388.86710061\n",
      "ll = -1388.8652977\n",
      "ll = -1388.86218509\n",
      "ll = -1388.85775395\n",
      "ll = -1388.9512525\n",
      "ll = -1388.85707261\n",
      "ll = -1388.85139426\n",
      "ll = -1388.84685376\n",
      "ll = -1388.84519005\n",
      "ll = -1388.84460278\n",
      "ll = -1392.06401741\n",
      "ll = -1388.84456095\n",
      "ll = -1388.84411519\n",
      "ll = -1388.84274347\n",
      "ll = -1388.83980052\n",
      "ll = -1388.83545289\n",
      "ll = -1388.83163881\n",
      "ll = -1388.83152022\n",
      "ll = -1388.83087815\n",
      "ll = -1388.82959796\n",
      "ll = -1388.82813424\n",
      "ll = -1388.83650215\n",
      "ll = -1388.82754333\n",
      "ll = -1388.82617121\n",
      "ll = -1405.21819103\n",
      "ll = -1388.82607567\n",
      "ll = -1388.82349739\n",
      "ll = -1389.0884086\n",
      "ll = -1388.82119169\n",
      "ll = -1388.81694808\n",
      "ll = -1388.80417909\n",
      "ll = -1388.80058901\n",
      "ll = -1388.81787993\n",
      "ll = -1388.79979554\n",
      "ll = -1388.79689435\n",
      "ll = -1388.79477507\n",
      "ll = -1388.79259795\n",
      "ll = -1388.79133551\n",
      "ll = -1388.79522438\n",
      "ll = -1388.79093038\n",
      "ll = -1388.78909867\n",
      "ll = -1388.78296099\n",
      "ll = -1388.75596013\n",
      "ll = -1388.74061787\n",
      "ll = -1388.70546509\n",
      "ll = -1388.69736541\n",
      "ll = -1388.8720161\n",
      "ll = -1388.69730554\n",
      "ll = -1388.69607359\n",
      "ll = -1388.69585577\n",
      "ll = -1388.69570828\n",
      "ll = -1388.69527348\n",
      "ll = -1388.69479849\n",
      "ll = -1388.76384258\n",
      "ll = -1388.69478015\n",
      "ll = -1388.6943154\n",
      "ll = -1388.69413596\n",
      "ll = -1388.6941008\n",
      "ll = -1388.69409207\n",
      "ll = -1388.6940743\n",
      "ll = -1388.69404143\n",
      "ll = -1388.69469526\n",
      "ll = -1388.69403841\n",
      "Final log likelihood = -1388.69403841\n"
     ]
    }
   ],
   "source": [
    "# Use a library function to run gradient descent (or you can implement yourself!)\n",
    "theta,l,info = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, args = (X_train, y_train, 1.0))\n",
    "print \"Final log likelihood =\", -l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_predictions = []\n",
    "for i in range(len(X)/2):\n",
    "    if inner(X_train[i], theta) > 0:\n",
    "        train_predictions.append(1)\n",
    "    else:\n",
    "        train_predictions.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy=  0.71335238873\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = sum([z[0] == z[1] for z in zip(train_predictions, y_train)]) * 1.0 / len(train_predictions)\n",
    "print 'train_accuracy= ', train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "for i in range(len(X)/2):\n",
    "    if inner(X_test[i], theta) > 0:\n",
    "        test_predictions.append(1)\n",
    "    else:\n",
    "        test_predictions.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy=  0.76929358922\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = sum([z[0] == z[1] for z in zip(test_predictions, y_test)]) * 1.0 / len(test_predictions)\n",
    "print 'test_accuracy= ', test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
