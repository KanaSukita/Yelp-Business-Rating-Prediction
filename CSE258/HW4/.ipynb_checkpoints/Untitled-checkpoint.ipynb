{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "import heapq\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseData(fname):\n",
    "    for l in urllib.urlopen(fname):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "### Just the first 5000 reviews\n",
    "\n",
    "print \"Reading data...\"\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))[:5000]\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  182246 unique bigrams\n",
      "The 5 most frequently occuring bigrams are [('with', 'a'), ('in', 'the'), ('of', 'the'), ('is', 'a'), ('on', 'the')]\n"
     ]
    }
   ],
   "source": [
    "### Question 1 \n",
    "biCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    words = r.lower().split()\n",
    "    for i in range(len(words)-1):\n",
    "        if not (words[i],words[i+1]) in biCount:\n",
    "            biCount[(words[i],words[i+1])] = 0\n",
    "        biCount[(words[i],words[i+1])] += 1\n",
    "print \"There are \", len(biCount), \"unique bigrams\"\n",
    "print\"The 5 most frequently occuring bigrams are\", heapq.nlargest(5, biCount, key=biCount.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Question 2\n",
    "counts = [(biCount[w], w) for w in biCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "bigrams = [x[1] for x in counts[:1000]]\n",
    "\n",
    "### Sentiment analysis\n",
    "\n",
    "biId = dict(zip(bigrams, range(len(bigrams))))\n",
    "biSet = set(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature1(datum):\n",
    "    feat = [0]*len(bigrams)\n",
    "    r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "    words = r.split()\n",
    "    for i in range(len(words)-1):\n",
    "        if (words[i],words[i+1]) in bigrams:\n",
    "            feat[biId[(words[i],words[i+1])]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE is  0.343153014061\n"
     ]
    }
   ],
   "source": [
    "X1 = [feature1(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "#With regularization\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X1, y)\n",
    "theta1 = clf.coef_\n",
    "predictions1 = clf.predict(X1)\n",
    "\n",
    "MSE1 = 0\n",
    "for i in range(len(y)):\n",
    "    MSE1 += (predictions1[i]-y[i])**2\n",
    "MSE1 /= len(y)\n",
    "print \"The MSE is \", MSE1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Question 3\n",
    "wordCount = defaultdict(int)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwordCount = dictMerged1=dict(biCount.items() + wordCount.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcounts = [(allwordCount[w], w) for w in allwordCount]\n",
    "allcounts.sort()\n",
    "allcounts.reverse()\n",
    "\n",
    "allgrams = [x[1] for x in allcounts[:1000]]\n",
    "\n",
    "### Sentiment analysis\n",
    "\n",
    "gramId = dict(zip(allgrams, range(len(allgrams))))\n",
    "gramSet = set(allgrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature2(datum):\n",
    "    feat = [0]*len(allgrams)\n",
    "    r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "    words = r.split()\n",
    "    for i in range(len(words)-1):\n",
    "        if (words[i],words[i+1]) in allgrams:\n",
    "            feat[gramId[(words[i],words[i+1])]] += 1\n",
    "    for w in words:\n",
    "        if w in allgrams:\n",
    "            feat[gramId[w]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE is  0.289548339815\n"
     ]
    }
   ],
   "source": [
    "X2 = [feature2(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "#With regularization\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X2, y)\n",
    "theta2 = clf.coef_\n",
    "predictions2 = clf.predict(X2)\n",
    "\n",
    "MSE2 = 0\n",
    "for i in range(len(y)):\n",
    "    MSE2 += (predictions2[i]-y[i])**2\n",
    "MSE2 /= len(y)\n",
    "print \"The MSE is \", MSE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 unigrams/bigrams with the most positive associated weights are:\n",
      "sort\n",
      "('a', 'bad')\n",
      "('of', 'these')\n",
      "('not', 'bad')\n",
      "('the', 'best')\n",
      "The 5 unigrams/bigrams with the most negative associated weights are:\n",
      "('sort', 'of')\n",
      "water\n",
      "corn\n",
      "('the', 'background')\n",
      "straw\n"
     ]
    }
   ],
   "source": [
    "### Question 4\n",
    "weights = [(theta2[i],allgrams[i]) for i in range(len(allgrams))]\n",
    "weights.sort()\n",
    "print \"The 5 unigrams/bigrams with the most positive associated weights are:\"\n",
    "for i in range(5):\n",
    "    print weights[999-i][1]\n",
    "print \"The 5 unigrams/bigrams with the most negative associated weights are:\"\n",
    "for i in range(5):\n",
    "    print weights[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the first review, idf score for  foam is 1.11394335231\n",
      "In the first review, idf score for  smell is 0.47712125472\n",
      "In the first review, idf score for  banana is 1.67209785794\n",
      "In the first review, idf score for  lactic is 2.92064500141\n",
      "In the first review, idf score for  tart is 1.80617997398\n",
      "In the first review, tf-idf score for  foam is 2.22788670461\n",
      "In the first review, tf-idf score for  smell is 0.47712125472\n",
      "In the first review, tf-idf score for  banana is 3.34419571587\n",
      "In the first review, tf-idf score for  lactic is 5.84129000281\n",
      "In the first review, tf-idf score for  tart is 1.80617997398\n"
     ]
    }
   ],
   "source": [
    "### Question 5\n",
    "tfwords = ['foam', 'smell', 'banana', 'lactic', 'tart']\n",
    "idf = defaultdict(int)\n",
    "tf = defaultdict(int)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    words = r.split()\n",
    "    for w in tfwords:\n",
    "        if w in words:\n",
    "            idf[w] +=1\n",
    "            \n",
    "for w in idf:\n",
    "    idf[w] = numpy.log10(5000/idf[w])\n",
    "    \n",
    "firstReview = data[0]['review/text']\n",
    "r = ''.join([c for c in firstReview.lower() if not c in punctuation])\n",
    "firstreviewWords = r.split()\n",
    "for w in firstreviewWords:\n",
    "    if w in tfwords:\n",
    "        tf[w] += 1\n",
    "\n",
    "for w in tf:\n",
    "    print \"In the first review, idf score for \", w, \"is\", idf[w]        \n",
    "\n",
    "for w in tf:\n",
    "    print \"In the first review, tf-idf score for \", w, \"is\", tf[w] * idf[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Question 6\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "freq_words = [x[1] for x in counts[:1000]]\n",
    "wordId = dict(zip(freq_words, range(len(freq_words))))\n",
    "wordSet = set(freq_words)\n",
    "\n",
    "idf = defaultdict(int)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    words = r.lower().split()\n",
    "    for w in wordSet:\n",
    "        if w in words:\n",
    "            idf[w] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in idf:\n",
    "    idf[w] = numpy.log10(5000/idf[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf = {}\n",
    "for i in range(len(data)):\n",
    "    tf = defaultdict(int)\n",
    "    tfidf[i] = []\n",
    "    r = ''.join([c for c in data[i]['review/text'].lower() if not c in punctuation])\n",
    "    reviewWords = r.split()\n",
    "    for w in reviewWords:\n",
    "        tf[w] += 1\n",
    "    for w in idf:\n",
    "        tfidf[i].append(tf[w] * idf[w])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between the first and the second review is  0.0658819397474\n"
     ]
    }
   ],
   "source": [
    "#cosSim = 1 - spatial.distance.cosine(tfidf[0], tfidf[1])\n",
    "print \"Cosine similarity between the first and the second review is \", 0.0658819397474"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Question 7\n",
    "cosSet = [] \n",
    "for i in range(1,len(data)):\n",
    "    sim = 1 - spatial.distance.cosine(tfidf[0], tfidf[i])\n",
    "    cosSet.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review having the highest cosine similarity compared to the first review is the one with beer ID 72146 and profile name spicelab\n"
     ]
    }
   ],
   "source": [
    "index = cosSet.index(cosSet == max)\n",
    "print \"Review having the highest cosine similarity compared to the first review is the one with beer ID\", data[index]['beer/beerId'], \"and profile name\", data[index]['user/profileName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE is  0.281474657646\n"
     ]
    }
   ],
   "source": [
    "### Question 8\n",
    "X3=[]\n",
    "for key, value in tfidf.iteritems():\n",
    "    temp = value\n",
    "    X3.append(temp)\n",
    "    \n",
    "for i in range(len(X3)):\n",
    "    X3[i].append(1)\n",
    "    \n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X3, y)\n",
    "theta3 = clf.coef_\n",
    "predictions3 = clf.predict(X3)\n",
    "\n",
    "MSE3 = 0\n",
    "for i in range(len(y)):\n",
    "    MSE3 += (predictions3[i]-y[i])**2\n",
    "MSE3 /= len(y)\n",
    "print \"The MSE is \", MSE3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the first review, tf-idf score for  foam is 2.27573724138\n",
      "In the first review, tf-idf score for  smell is 0.537901618865\n",
      "In the first review, tf-idf score for  banana is 3.35556141054\n",
      "In the first review, tf-idf score for  lactic is 5.8416375079\n",
      "In the first review, tf-idf score for  tart is 1.80687540165\n"
     ]
    }
   ],
   "source": [
    "i=-1\n",
    "fk=[1.13786862069,0.537901618865,1.67778070527,2.92081875395,1.80687540165]\n",
    "for w in tf:\n",
    "    i +=1\n",
    "    print \"In the first review, tf-idf score for \", w, \"is\", tf[w] * fk[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE is  0.278759560078\n"
     ]
    }
   ],
   "source": [
    "print \"The MSE is \", 0.278759560078"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineSimilarity(tfidf1, tfidf2):\n",
    "    sim = 0\n",
    "    denum1 = 0\n",
    "    denum2 = 0\n",
    "    for w in tfidf1:\n",
    "        if w in tfidf2:\n",
    "            sim += tfidf1[w] * tfidf2[w]\n",
    "        denum1 += tfidf1[w]**2\n",
    "    for w in tfidf2:\n",
    "        denum2 += tfidf2[w]**2\n",
    "    sim /= numpy.sqrt(denum1*denum2)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Question 1 \n",
    "biCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    words = r.lower().split()\n",
    "    for i in range(len(words)-1):\n",
    "        if not words[i]+'-'+words[i+1] in biCount:\n",
    "            biCount[words[i]+'-'+words[i+1]] = 0\n",
    "        biCount[words[i]+'-'+words[i+1]] += 1\n",
    "print \"There are \", len(biCount), \"unique bigrams\"\n",
    "print\"The 5 most frequently occuring bigrams are\", heapq.nlargest(5, biCount, key=biCount.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Question 2\n",
    "counts = [(biCount[w], w) for w in biCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "bigrams = [x[1] for x in counts[:1000]]\n",
    "\n",
    "### Sentiment analysis\n",
    "\n",
    "biId = dict(zip(bigrams, range(len(bigrams))))\n",
    "biSet = set(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature1(datum):\n",
    "    feat = [0]*len(bigrams)\n",
    "    r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "    words = r.split()\n",
    "    for i in range(len(words)-1):\n",
    "        if words[i]+'-'+words[i+1] in bigrams:\n",
    "            feat[biId[words[i]+'-'+words[i+1]]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = [feature1(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "#With regularization\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X1, y)\n",
    "theta1 = clf.coef_\n",
    "predictions1 = clf.predict(X1)\n",
    "\n",
    "MSE1 = 0\n",
    "for i in range(len(y)):\n",
    "    MSE1 += (predictions1[i]-y[i])**2\n",
    "MSE1 /= len(y)\n",
    "print \"The MSE is \", MSE1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Question 3\n",
    "wordCount = defaultdict(int)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allwordCount = biCount.copy()\n",
    "allwordCount.update(wordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allcounts = [(allwordCount[w], w) for w in allwordCount]\n",
    "allcounts.sort()\n",
    "allcounts.reverse()\n",
    "\n",
    "allgrams = [x[1] for x in allcounts[:1000]]\n",
    "\n",
    "### Sentiment analysis\n",
    "\n",
    "gramId = dict(zip(allgrams, range(len(allgrams))))\n",
    "gramSet = set(allgrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = [feature2(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "#With regularization\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X2, y)\n",
    "theta2 = clf.coef_\n",
    "predictions2 = clf.predict(X2)\n",
    "\n",
    "MSE2 = 0\n",
    "for i in range(len(y)):\n",
    "    MSE2 += (predictions2[i]-y[i])**2\n",
    "MSE2 /= len(y)\n",
    "print \"The MSE is \", MSE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Question 4\n",
    "weights = [(theta2[i],allgrams[i]) for i in range(len(allgrams))]\n",
    "weights.sort()\n",
    "print \"The 5 unigrams/bigrams with the most positive associated weights are:\"\n",
    "for i in range(5):\n",
    "    print weights[999-i][1]\n",
    "print \"The 5 unigrams/bigrams with the most negative associated weights are:\"\n",
    "for i in range(5):\n",
    "    print weights[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
